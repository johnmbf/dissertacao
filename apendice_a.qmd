# Apêndice - A {#sec-apendice-a}

```{r, setup-apendice-a}
#| include: false

knitr::opts_chunk$set(
  warning = FALSE, error = FALSE, message = FALSE
)
```

Introdução à metodologia

## Coleta de dados

Os dados foram coletados do portal Corte Aberta do STF, painéis estatísticos de controle concentrado que podem ser acessados [aqui](https://transparencia.stf.jus.br/extensions/controle_concentrado/controle_concentrado.html). Foram baixados três tabelas do portal e armazenados na pasta `DATA/RAW/`, conforme @tbl-dados-raw abaixo:

::: {#tbl-dados-raw}
| Tabela | Descrição | Arquivo | Data |
| ------ | --------- | ----- | ----- |
| Processos | Contém as informações gerais sobre os processos de controle concentrado | [raw_processos.xlsx](DATA/RAW/raw_processos.xlsx) | 06/06/2025 |
| Decisões | Contém as informações sobre as decisões tomadas em sede de controle concentrado | [raw_decisoes.xlsx](DATA/RAW/raw_decisoes.xlsx) | 06/06/2025 |
| Legitimados | Contém as informações sobre os legitimados ativos e legitimados passivos nas ações de controle concentrado | [raw_legitimados.xlsx](DATA/RAW/raw_legitimados.xlsx) | 06/06/2025 |
:::

Uma vez baixados os dados, eles foram importados utilizando a função `readxl::read_xlsx()`:

```{r, imp-1, eval=FALSE}
# Importa os processos
raw_processos <- readxl::read_xlsx("DATA/RAW/raw_processos.xlsx", na = "*NI*") # <1>

# Importa as decisões
raw_decisoes <- readxl::read_xlsx("DATA/RAW/raw_decisoes.xlsx",
  na = "*NI*",
  col_types = c("guess", "date", "guess", "guess", "guess", "guess") # <2>
)

# Importa os legitimados
raw_legitimados <- readxl::read_xlsx("DATA/RAW/raw_legitimados.xlsx",
  na = "*NI*"
)
```
1. na = "\*NI\*": o STF utiliza o código \*NI\* para dados faltantes.
2. col_types: foi preciso na tabela de decisões indicar expressamente o tipo de dado da coluna data

Após importar os dados, salvei eles em formato `.rds` para leitura mais posterior mais rápida:

```{r, imp-2, eval=FALSE}
# Salvar os arquivos raw em rds
saveRDS(raw_processos, "DATA/RAW/raw_processos.rds")
saveRDS(raw_decisoes, "DATA/RAW/raw_decisoes.rds")
saveRDS(raw_legitimados, "DATA/RAW/raw_legitimados.rds")
```

O segundo conjunto de dados foram obtidos a partir da raspagem de dados no portal do STF. Primeiro, extraiu-se os dados sobre decisões monocráticas e acórdãos, depois, com base na tabela de acórdãos, foram baixados os arquivos em `.pdf` dos acórdãos. Para isso, foi utilizado o pacote `decJ`.

```{r, dec-imp, eval=FALSE}
# Extrai as decisões monocráticas
raw_monocraticas <- decJ::stf_jurisprudencia(
  classe = "ADPF",
  base = 'decisoes',
  quantidade = 3000
)

# Extrai os acórdãos
raw_acordaos <- decJ::stf_jurisprudencia(
  classe = "ADPF",
  base = "acordaos",
  quantidade = 3000
)

# Salva os arquivos raw em rds
saveRDS(raw_monocraticas, "DATA/RAW/raw_monocraticas.rds")
saveRDS(raw_acordaos, "DATA/RAW/raw_acordaos.rds")
```

A função `decJ::stf_jurisprudencia()` funciona da seguinte forma:

```{r, decj-juris, eval=FALSE}
# Função stf_jurisprudencia do pacote decJ

stf_jurisprudencia = function(busca = NULL, classe = NULL, base = c("acordaos", "decisoes"), quantidade = 25){

  header <- httr::add_headers("User-Agent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.51") # <1>

  if (!is.null(busca) & is.null(classe)) { # <2>
    body <- busca_jurisprudencia # <2>
    body$query$bool$filter[[1]]$query_string$query <- busca # <2>
    body$post_filter$bool$must[[1]]$term$base <- base # <2>
  } else if (is.null(busca) & !is.null(classe)) { # <2>
    body <- busca_classe # <2>
    body$query$bool$filter$query_string$query <- classe # <2>
    body$post_filter$bool$must$term$base <- base # <2>
  } else if ((!is.null(busca) & !is.null(classe))) { # <2>
    cli::cli_alert_danger("Essa funcao so funciona com busca por palavras chaves OU por classe. Ainda estamos desenvolvendo uma forma de trabalhar com as duas buscas juntas.") # <2>
    return(NULL) # <2>
  } # <2>

  num_iteracoes <- ceiling(quantidade / 250) # <3>

  if (quantidade > 250) {
    body$size <- 250
  } else {
    body$size <- quantidade
  }
 
  purrr::map_dfr(1:num_iteracoes, purrr::slowly(~{ 
    body$from <- (.x - 1) * 250
    htmlSTF <- httr::POST( # <4>
      "https://jurisprudencia.stf.jus.br/api/search/search", # <4>
      body = body, # <4>
      encode = "json", header # <4>
    ) # <4>
    getContent <- jsonlite::fromJSON(httr::content(htmlSTF, "text")) # <4>
    dados <- getContent$result$hits$hits$`_source` # <4>
  }, rate = purrr::rate_delay(5)), .progress = list(format = "Extraindo {cli::pb_bar} {cli::pb_elapsed}")) 
}
```
1. Adicionar um User_Agent
2. A função ainda não consegue fazer buscas por palavras-chave e classe, portanto, nesse momento ela identifica se a busca está sendo feita por palavras chave ou por classe e, então, utiliza o `body` da requisição correto para o tipo de busca. Caso o usuário coloque classe e palavra-chave, a função retorna um erro.
3. Como a API do STF não permite fazer mais do que 250 buscas por vez, aqui ele verifica a quantidade que está sendo buscada e divide por 250 para identificar a quantidade de requisições que serão necessárias.
4. A requisição é feita e como resultado temos uma tabela com os dados solicitados.

Estas então foram as formas de coletar os dados brutos. Abaixo podemos observar a estrutura dessas tabelas:

```{r, imp-3, include=FALSE}
# Faz a leitura dos arquivos raw para utilizar no script
raw_processos <- readRDS('DATA/RAW/raw_processos.rds')
raw_decisoes <- readRDS('DATA/RAW/raw_decisoes.rds')
raw_legitimados <- readRDS('DATA/RAW/raw_legitimados.rds')
raw_monocraticas <- readRDS('DATA/RAW/raw_monocraticas.rds')
raw_acordaos <- readRDS('DATA/RAW/raw_acordaos.rds')
```

```{r, imp-4, echo=FALSE}
# Cria uma tabela com as informações dos dados raw
tibble::tribble(
  ~"Tabela", ~"Nº Colunas", ~"Nº Linhas", ~"Nº de Dados",
  "raw_processos", ncol(raw_processos), nrow(raw_processos), ncol(raw_processos) * nrow(raw_processos),
  "raw_decisoes", ncol(raw_decisoes), nrow(raw_decisoes), ncol(raw_decisoes) * nrow(raw_decisoes),
  "raw_legitimados", ncol(raw_legitimados), nrow(raw_legitimados), ncol(raw_legitimados) * nrow(raw_legitimados),
  "raw_acordaos", ncol(raw_acordaos), nrow(raw_acordaos), ncol(raw_acordaos) * nrow(raw_acordaos),
  "raw_monocraticas", ncol(raw_monocraticas), nrow(raw_monocraticas), ncol(raw_monocraticas) * nrow(raw_monocraticas)
) |> knitr::kable()
```

## Limpeza dos dados

Uma vez obtidos os dados brutos, foi preciso fazer uma faxina inicial. Primeiro, limpei o nome das variáveis:

```{r, limp-1}
# Limpa o nome das variáveis
clean_processos <- janitor::clean_names(raw_processos)
clean_decisoes <- janitor::clean_names(raw_decisoes)
clean_legitimados <- janitor::clean_names(raw_legitimados)
clean_acordaos <- janitor::clean_names(raw_acordaos)
clean_monocraticas <- janitor::clean_names(raw_monocraticas)
```

Após a limpeza dos nomes das variáveis de todas as tabelas, passei a limpar tabelas específicas. Começando pela tabela de processos (`clean_processos`).

```{r, limp-2}
clean_processos <- clean_processos |>
  # seleciona as colunas que serão utilizadas
  dplyr::select(
    processo, link_processo, relator_atual, ramo_do_direito, assunto_relacionado, data_autuacao, data_transito_julgado, data_baixa, em_tramitacao, tem_rito_art_12, legislacao
  ) |>
  # transforma as colunas de data 
  dplyr::mutate(
    data_autuacao = lubridate::ymd(as.Date(data_autuacao)),
    data_transito_julgado = lubridate::ymd(as.Date(data_transito_julgado)),
    data_baixa = lubridate::ymd(as.Date(data_baixa, format = "%d/%m/%Y"))
  ) |>
  # separa processo em classe e numero
  tidyr::separate(
    processo,
    into = c("classe", "numero"),
    sep = "\\s"
  ) |>
  # separa os assuntos relacionados
  tidyr::separate_rows(
    assunto_relacionado,
    sep = "\\|"
  ) |>
  # separa a legislação
  tidyr::separate_rows(
    legislacao,
    sep = "\\r"
  )

# Salva a tabela limpa
saveRDS(clean_processos, "DATA/CLEAN/clean_processos.rds")
```

A segunda tabela que apliquei a faxina foi a tabela que contém as decisões (`clean_decisoes`). A tabela criada considera apenas as decisões cujo resultado foi procedente, improcedente, procedente em parte ou prejudicado. Posteriormente, as ações que tiverem "em tramitação" igual a "não" na tabela de processos e não retornarem esses resultados, serão consideradas sem resolução de mérito.

```{r, limp-3}
clean_decisoes <- clean_decisoes |>
  # retira a coluna observação e descrição
  dplyr::select(-observacao, descricao) |>
  # transforma a coluna de data 
  dplyr::mutate(data = lubridate::ymd(as.Date(data))) |>
  # separa processo em classe e numero |>
  tidyr::separate(
    processo,
    into = c("classe", "numero"),
    sep = "\\s"
  ) |>
  # transforma o texto da coluna descricao em minusculo
  dplyr::mutate(descricao = stringr::str_to_lower(descricao))

# Salva a tabela limpa
saveRDS(clean_decisoes, "DATA/CLEAN/clean_decisoes.rds")
```

A teceira tabela envolve os legitimados (`clean_legitimados`):

```{r, limp-4}
clean_legitimados <- clean_legitimados |>
  # retira os acentos
  dplyr::mutate(dplyr::across(c("legitimado_polo_ativo", "legitimado_polo_passivo"), decJ::utilitario_remover_acentos)) |>
  # separa processo em classe e numero
  tidyr::separate(
    processo,
    into = c("classe", "numero"),
    sep = "\\s"
  )

# Salva a tabela limpa
saveRDS(clean_legitimados, "DATA/CLEAN/clean_legitimados.rds")
```

A limpeza da tabela com as decisões monocráticas e os acórdãos envolveu, basicamente, selecionar as colunas de interesse.

```{r, limp-5}
clean_monocraticas <- clean_monocraticas |>
  # seleciona e renomeia as colunas de interesse
  dplyr::select(id, uf = procedencia_geografica_uf_sigla, numero = processo_numero, data = julgamento_data, texto = decisao_texto)

clean_acordaos <- clean_acordaos |>
  # seleciona e renomeia as colunas de interesse
  dplyr::select(id, uf = procedencia_geografica_uf_sigla, numero = processo_numero, data = julgamento_data, texto = ementa_texto, url = inteiro_teor_url)

# Salva as tabelas limpas
saveRDS(clean_monocraticas, "DATA/CLEAN/clean_monocraticas.rds")
saveRDS(clean_acordaos, "DATA/CLEAN/clean_acordaos.rds")
```

Serão feitas limpezas específicas dos dados a depender da análise. Essas limpezas estarão descritas no momento da análise no capítulo respectivo. Ademais, todo o código está compilado no @sec-code. As tabelas salvas serão carregas sempre antes de serem utilizadas nas análises, permitindo que o ponto de partida das informações sejam os descritos nessa seção.

## Análise quantitativa

Estatísticas descritivas...

### Análise de Sobrevivência

Este trabalho incorpora uma abordagem quantitativa para investigar um aspecto crucial da prestação jurisdicional: o tempo. A duração de um processo judicial não é um mero detalhe procedimental; ela representa o tempo em que a sociedade, os atores políticos e os cidadãos aguardam por uma definição do judiciário sobre questões de elevada magnitude. A morosidade ou a celeridade do STF impacta diretamente a segurança jurídica, a estabilidade das relações políticas e a própria efetividade dos direitos. Para mensurar e analisar rigorosamente este fator temporal, a metodologia empregada será a análise de sobrevivência, uma técnica estatística que permite estudar a duração da tramitação processual até a ocorrência de um evento de interesse, que, no escopo desta pesquisa, foi definido como a baixa definitiva do processo.

A análise de sobrevivência é um conjunto de métodos estatísticos cujo objetivo primordial é analisar o tempo decorrido desde um marco inicial até a ocorrência de um determinado evento. Embora suas origens remontem às ciências médicas — onde era classicamente utilizada para estudar o tempo de sobrevida de pacientes após um diagnóstico ou tratamento —, sua aplicabilidade foi expandida para diversas outras áreas, como engenharia (análise de falha de equipamentos), economia (duração do desemprego) e, como no presente caso, o direito. No contexto jurídico-processual, o "tempo de sobrevivência" de um processo pode ser entendido como o período em que ele permanece ativo, ou "vivo", no sistema de justiça. O "evento" de interesse, análogo à "morte" no estudo clínico, é a sua conclusão, ou seja, a sua baixa definitiva após o trânsito em julgado. Esta metodologia permite-nos ir além de simples médias ou medianas de duração, oferecendo uma visão dinâmica de como a probabilidade de um processo ser finalizado evolui ao longo do tempo.

Um dos desafios mais significativos na análise de dados temporais em pesquisas jurídicas é a presença de "dados censurados". A censura ocorre quando não observamos o evento de interesse para todos os sujeitos da nossa amostra durante o período de estudo. Em nossa pesquisa, que abrange as ADPFs distribuídas até uma data de corte específica, inevitavelmente encontraremos processos que, ao final do período de coleta de dados, ainda estão em tramitação. Esses processos são os nossos dados censurados. Simplesmente ignorá-los ou tratá-los como se tivessem sido finalizados na data de corte introduziria um viés severo na análise, subestimando drasticamente o tempo real de tramitação. A grande vantagem da análise de sobrevivência, e especificamente do método de Kaplan-Meier que adotaremos, é sua capacidade de incorporar essa informação parcial dos dados censurados de forma elegante e precisa, utilizando a informação de que eles "sobreviveram" pelo menos até o final do período de observação, sem presumir quando serão de fato concluídos.

Para contornar o problema dos dados censurados e estimar a função de sobrevivência dos processos de ADPF, esta dissertação empregará o estimador de Kaplan-Meier. Trata-se de um método não paramétrico, o que representa uma vantagem considerável, pois não nos obriga a fazer pressuposições sobre a distribuição estatística subjacente dos tempos de tramitação dos processos. Em outras palavras, não precisamos assumir que os tempos de julgamento seguem uma forma matemática pré-definida. O método de Kaplan-Meier utiliza a informação disponível no momento exato em que cada processo é finalizado para recalcular, passo a passo, a probabilidade de um processo qualquer "sobreviver", ou seja, permanecer ativo, para além daquele ponto no tempo. O resultado é uma estimativa mais realista e detalhada da dinâmica temporal da jurisdição constitucional, apresentada geralmente por meio de uma função em escada, conhecida como curva de Kaplan-Meier.

A fórmula matemática que fundamenta o estimador de Kaplan-Meier, embora possa parecer complexa à primeira vista, baseia-se em uma lógica bastante intuitiva. A probabilidade de um processo sobreviver para além de um tempo $t$, denotada por $S(t)$, é calculada pelo produto das probabilidades de sobrevivência em cada um dos momentos em que ocorre um evento (a baixa de um processo) até o tempo $t$. A fórmula é a seguinte:

$$
S(t) = \prod_{i:t_i\leq t} (1 - \frac{d_i}{n_i})
$$ {#eq-kaplan-meier}

$S(t)$ é a função de sobrevivência, ou seja, a probabilidade estimada de que uma ADPF inda esteja em tramitação após um tempo $t$. O símbolo $\prod$ é o produtório, que indica a multiplicação sucessiva de termos. O índice $t_i\leq t$ significa que estamos multiplicando os termos para todos os momentos $t_i$ em que um processo foi baixado, desde o início do acompanhamento até o tempo $t$. O elemento $d_i$ representa o número de processos que tiveram baixa exatamente no tempo $t_i$. Por fim, $n_i$ representa o número total de processos que estavam sob risco de serem baixados imediatamenteantes do tempo $t_i$,  isto é, todos os processos que ainda estavam ativos naquele momento.

O termo central $\frac{d_i}{n_i}$ representa o risco instantâneo de um processo ser baixado no tempo $t_i$. É a proporção de processos baixados dentre todos que estavam ativos. Consequentemente, a expressão $(1-\frac{d_i}{n_i})$ representa a probabilidade de um processo não ser baixado naquele exato momento, ou seja, de sobreviver ao tempo $t_i$, dado que ele já havia sobrevivido até ali. Ao multiplicar essas probabilidade de sobrevivência em cada etapa, calculamos a probabilidade acumulada de um processo ter sobrevivido a todos os momentos de risco até o tempo $t$. 

Ao quantificar a dimensão temporal da prestação jurisdicional em ADPFs de forma precisa, controlando os efeitos dos processos ainda em curso, esta pesquisa pode fundamentar suas conclusões em evidências sistemáticas, e não apenas em observações anedóticas ou estudos de caso isolados. A análise da curva de sobrevivência permitirá identificar períodos críticos na tramitação dos processos e oferecerá uma base sólida para discutir a capacidade institucional do STF em responder, em tempo hábil, às complexas demandas que lhe são apresentadas pelos atores políticos.

Após a aplicação do estimador de Kaplan-Meier, que nos permite descrever a probabilidade de uma ADPF permanecer em tramitação ao longo do tempo, a investigação avança para uma questão mais complexa e explicativa: quais fatores ou características influenciam essa duração? Enquanto a análise de Kaplan-Meier nos mostra o quê acontece com a taxa de finalização dos processos, ela não nos informa o porquê. Por que algumas ADPFs são julgadas em poucos meses, enquanto outras perduram por mais de uma década no Supremo Tribunal Federal (STF)? Para responder a essa pergunta, a metodologia desta pesquisa emprega o modelo de regressão de riscos proporcionais de Cox. Este é um passo analítico subsequente e mais sofisticado, que nos permite avaliar o impacto de múltiplas variáveis (covariáveis) sobre o tempo de tramitação processual, identificando os fatores que aceleram ou retardam a baixa definitiva de uma ADPF.



### Regressão Logística

## Análise qualitativa

Iramuteq... e quanteda?